% !TEX root = 0-main.tex

\section{\algnamenospace}
\label{sec:algo}

At the core of the PAM algorithm is the $O(n^2)$ BUILD search \eqref{eqn:build-next-medoid}, which is repeated $k$ times for initialization, and the $O(kn^2)$ SWAP search \eqref{eqn:next-swap}, which is repeated until convergence. 
We first show that both searches share a similar mathematical structure, and then show that such a structure can be optimized efficiently using a bandit-based randomized algorithm, thus giving rise to \algnamenospace. 
Rewriting the BUILD search \eqref{eqn:build-next-medoid} and the SWAP search \eqref{eqn:next-swap} in terms of the change in total loss yields
\begin{align}
    \text{BUILD:~~~~}& \argmin_{x \in \mathcal{X} \setminus \mathcal{M}_{l}} \frac{1}{n} \sum_{j=1}^n \left[ \left(d(x, x_j) - \min_{m' \in \mathcal{M}_{l}} d(m', x_j) \right)  \wedge 0\right], \label{eqn:build_search}\\
    \text{SWAP:~~~~}& \argmin_{(m,x) \in \mathcal{M} \times (\mathcal{X} \setminus \mathcal{M}) } \frac{1}{n} \sum_{j=1}^n \left[ \left(d(x, x_j) - \min_{m' \in \mathcal{M}\setminus \{m\}} d(m', x_j) \right)\wedge 0\right].  \label{eqn:swap_search}
\end{align}
One may notice that the above two problems share the following similarities.
First, both are searching over a finite set of parameters: $n-l$ points in the BUILD search and $k(n-k)$ swaps in the SWAP search. 
Second, both objective functions have the form of an average of an $O(1)$ function evaluated over a finite set of reference points. 
We formally describe the shared structure:
\begin{align} \label{eqn:genetic_optimiation}
    \text{Shared Problem:~~~~} \argmin_{x \in \mathcal{S}_{\text{tar}} } \frac{1}{\vert \mathcal{S}_{\text{ref}} \vert } \sum_{x_j \in \mathcal{S}_{\text{ref}}} g_x(x_j), 
\end{align}
for target points $\mathcal{S}_{\text{tar}} $, reference points $\mathcal{S}_{\text{ref}}$, and an objective function $g_x(\cdot)$ that depends on the target point $x$. Then both the BUILD search and the SWAP search can be written as instances of Problem \eqref{eqn:genetic_optimiation} with:
\begin{align}
    & \text{BUILD:~~} 
    \mathcal{S}_{\text{tar}}=\mathcal{X} \setminus \mathcal{M}_{l},~
    \mathcal{S}_{\text{ref}} = \mathcal{X},~
    g_x(x_j) = \left(d(x, x_j) - \min_{m' \in \mathcal{M}_{l}} d(m', x_j) \right)  \wedge 0, \label{eqn:build_instance}\\
    & \text{SWAP:~~} 
    \mathcal{S}_{\text{tar}}=\mathcal{M} \times (\mathcal{X} \setminus \mathcal{M}),~
    \mathcal{S}_{\text{ref}} = \mathcal{X},~
    g_x(x_j) =  \left(d(x, x_j) - \min_{m' \in \mathcal{M} \setminus \{m\}} d(m', x_j) \right)\wedge 0. \label{eqn:swap_instance}
\end{align}
% \mo{Previous eqn spills into margin. acceptable?}
Crucially, in the SWAP search, each \textit{pair} of medoid-and-non-medoid points $(m,x)$ is treated as one target point in $\mathcal{S}_{\text{tar}}$ in this new formulation.

\subsection{Adaptive search for the shared problem}
Recall that the computation of $g(x_j)$ is $O(1)$.
A naive, explicit method would require $O(\vert \mathcal{S}_{\text{tar}} \vert \vert \mathcal{S}_{\text{ref}} \vert)$ computations of $g(x_j)$ to solve Problem \eqref{eqn:genetic_optimiation}. 
However, as shown in previous works \cite{bagaria2018medoids,bagaria2018adaptive}, a randomized search would return the correct result with high confidence in $O( \vert \mathcal{S}_{\text{tar}}\vert \log  \vert \mathcal{S}_{\text{ref}} \vert)$ computations of $g(x_j)$.
Specifically, for each target $x$ in Problem \eqref{eqn:genetic_optimiation}, let $\mu_x = \frac{1}{\vert \mathcal{S}_{\text{ref}} \vert } \sum_{x_j \in \mathcal{S}_{\text{ref}}} g_x(x_j)$ denote its objective function. Computing $\mu_x$ exactly takes $O(\vert \mathcal{S}_{\text{ref}} \vert)$ computations of $g(x_j)$, but we can instead estimate $\mu_x$ with fewer computations by drawing $J_1,J_2,...,J_{n'}$ independent samples uniformly with replacement from $[|\mathcal{S_{\text{ref}}}|]$.
Then, $E[g(x_{J_i})] = \mu_x$ and $\mu_x$ can be estimated as $\hat{\mu}_x = \frac{1}{n'} \sum_{i=1}^{n'} g(x_{J_i})$, where $n'$ determines the estimation accuracy. 
To estimate the solution to Problem \eqref{eqn:genetic_optimiation} with high confidence, we can then choose to sample different targets in $\mathcal{S}_{\text{tar}}$ to different degrees of accuracy. 
Intuitively, promising targets with small values of $\mu_x$ should be estimated with high accuracy, while less promising ones can be discarded without being evaluated on too many reference points. 

% Furthermore, if we change our goal to estimating the solution in Problem \eqref{eqn:genetic_optimiation} with high confidence, then we can choose to sample different points in $\mathcal{S}_{\text{tar}}$ with different accuracy. 
% Intuitively, promising points with small values of $\mu_x$ should be estimated with high accuracy while less promising ones can be discarded without being evaluated on too many reference points. 

The specific adaptive estimation procedure is described in Algorithm \ref{alg:bandit_based_search}. 
It can be viewed as a batch version of the conventional UCB algorithm \cite{lai1985asymptotically,zhang2019adaptive} and is easier to implement.
The algorithm uses the set $\mathcal{S}_{\text{solution}}$ to track all potential solutions to Problem \eqref{eqn:genetic_optimiation}; $\mathcal{S}_{\text{solution}}$ is initialized as the set of all target points $\mathcal{S}_{\text{tar}}$. For each potential solution $x\in \mathcal{S}_{\text{solution}}$, the algorithm maintains its mean objective estimate $\hat{\mu}_x$ as well as a confidence interval $C_x$, where the latter depends on the exclusion probability $\delta$ as well as the dispersion parameter $\sigma_x$.

In each iteration, a new batch of reference points $\mathcal{S}_{\text{ref\_batch}}$ is evaluated for all potential solutions in $\mathcal{S}_{\text{solution}}$, making the estimate of $\hat{\mu}_x$ more accurate. 
Based on the current estimate, if a target's lower confidence bound $\hat{\mu}_x - C_x$ is still greater than the upper confidence bound of the most promising target $\min_{y}(\hat{\mu}_{y} + C_{y})$, we remove it from the set of possible solutions $\mathcal{S}_{\text{solution}}$. This process continues until there is only one point in $\mathcal{S}_{\text{solution}}$ or until we have sampled more reference points than in the whole reference set. In the latter case, we know that the difference between the remaining targets in $\mathcal{S}_{\text{solution}}$ is so subtle that an exact computation is more efficient. We then compute those targets' objectives exactly and return the best target in the set. 

% \martin{For completeness we need at least a description of \algname in the main paper. I don't think it's a good idea to move it completely to Supp.}
% We discuss further implementation optimizations to \algname in Appendices \ref{A0}.

\begin{algorithm}[t]

\caption{
\texttt{Adaptive-Search} (
$\mathcal{S}_{\text{tar}},
\mathcal{S}_{\text{ref}},
g_x(\cdot),
$batchsize,
$\delta$,
$\sigma_x$
) \label{alg:bandit_based_search}}
\begin{algorithmic}[1]
\State $\mathcal{S}_{\text{solution}} \leftarrow \mathcal{S}_{\text{tar}}$ \Comment{Set of potential solutions to Problem \eqref{eqn:genetic_optimiation}}
\State $n_{\text{used\_ref}} \gets 0$  \Comment{Number of reference points evaluated}
\State For all $x \in  \mathcal{S}_{\text{tar}}$, set $\hat{\mu}_x \leftarrow 0$, $C_x \leftarrow \infty$  \Comment{Initial mean and confidence interval for each arm}

\While{$n_{\text{used\_ref}} < \vert \mathcal{S}_{\text{ref}} \vert $ and $|\mathcal{S}_{\text{solution}}| > 1$} % and $C_y > 0$ for some arm $y$}
        \State Draw a batch of $\batchsize$ samples with replacement from reference $\mathcal{S}_{\text{ref\_batch}} \subset \mathcal{S}_{\text{ref}}$ 
        \ForAll{$x \in \mathcal{S}_{\text{solution}} $}
            \State $\hat{\mu}_x \leftarrow \frac{ n_{\text{used\_ref}} \hat{\mu}_x + \sum_{y \in \mathcal{S}_{\text{ref\_batch}}} g_x(y)}{n_{\text{used\_ref}} + \batchsize }$ \Comment{Update running mean}
            \State $C_x \gets \sigma_x \sqrt{  \frac{ 2 \log(\frac{1}{\delta}) } {n_{\text{used\_ref}} + \batchsize }}$
            \Comment{Update confidence interval}        
        \EndFor
    \State $\mathcal{S}_{\text{solution}} \leftarrow \{x : \hat{\mu}_x - C_x \leq \min_{y}(\hat{\mu}_{y} + C_{y})\}$ \Comment{Remove points that can no longer be solution}
    \State $n_{\text{used\_ref}} \leftarrow n_{\text{used\_ref}} + \batchsize$
\EndWhile
\If{$\vert \mathcal{S}_{\text{solution}} \vert$ = 1}
    \State \textbf{return} $x^* \in \mathcal{S}_{\text{solution}}$
\Else
    \State Compute $\mu_x$ exactly for all $x \in \mathcal{S}_{\text{solution}}$
    \State \textbf{return} $x^* = \argmin_{x \in \mathcal{S}_{\text{solution}}} \mu_x$
\EndIf
\end{algorithmic}
\end{algorithm}

\subsection{Algorithmic details \label{subsec:algdetails}}
\label{A0}

\textbf{Estimation of each $\sigma_x$:} \algname uses Algorithm \ref{alg:bandit_based_search} in both the BUILD step and each SWAP iteration, with input parameters specified in \eqref{eqn:build_instance} and \eqref{eqn:swap_instance}. In practice, $\sigma_x$ is not known \emph{a priori} and we estimate $\sigma_x$ for each $x \in |\mathcal{S}_{\text{tar}}|$ from the data. In the first batch of sampled reference points in Algorithm \ref{alg:bandit_based_search}, we estimate each $\sigma_x$ as:
\begin{equation}
\label{eqn:sigma_est}
    \sigma_x = {\rm STD}_{y \in \mathcal{S}_{\text{ref\_batch}}}g_x(y)
\end{equation}
where ${\rm STD}$ denotes standard deviation. Intuitively, this allows for smaller confidence intervals in later iterations, especially in the BUILD step, when we expect the average arm returns to become smaller as we add more medoids (since we are taking the minimum over a larger set on the RHS of Eq. \eqref{eqn:build-next-medoid}). We also allow for arm-dependent $\sigma_x$, as opposed to a fixed global $\sigma$, which allows for narrower confidence intervals for arms whose returns are heavily concentrated (e.g., distant outliers). 
Empirically, this results in significant speedups and results in fewer arms being computed exactly (Line 14 in Algorithm \ref{alg:bandit_based_search}). In all experiments, the batchsize is set to 100 and the error probability $\delta$ is set to $\delta = \frac{1}{1000\vert \mathcal{S}_{\text{tar}} \vert}$. Empirically, these values of batch size and this setting of $\delta$ are such that \algname recovers the same results in PAM in almost all cases.%, while still demonstrating the expected $O(\frac{n}{\log n})$ speedup.


\textbf{Combination with FastPAM1:} We also combine \algname with the FastPAM1 optimization \cite{schubert2019faster}. We discuss this optimization in Appendix \ref{A1}. 



% \clearpage
% UltraPAM, shown in Algorithm 1, is an algorithm to $k$ medoids of a given dataset. It uses techniques from the MAB literature, specifically the Upper Confidence Bound (UCB) algorithm, to identify the same medoids as prior approaches, such as PAM and FastPAM, with high probability, while running in significantly less time. The algorithmic complexity of UltraPAM is $O(kNlogN)$ in the BUILD step and each SWAP step, compared to $O(kN^2)$ in the BUILD and each SWAP step of PAM and FastPAM. \martin{Include the success probability because this is an probabilistic algorithm.}

% In the UltraPAM BUILD step, we intialize each medoid of the $k_{max}$ medoids one by one. 
% At each step in the outer loop, our goal is to find the non-medoid for which choosing it as the new medoid would lower the total loss the most. Intuitively, conditioned on the prior $k - 1$ medoids \ilan{I don't like this use of the word conditioned}, we view the non-medoids as "arms" in the MAB framework. 
% Pulling an arm corresponding to point $x_i$ corresponds to computing the change in Total Loss (Eq. 1) that would be induced on a single reference point, $x_{\rm ref}$ \martin{$x_{\text{ref}}$} by choosing $x_i$ as the $k^{th}$ \martin{$k$th} medoid. 
% Rather than computing this change in loss for every non-medoid candidate $x_i$ and every possible reference point $x_{\rm ref}$ as in PAM, we expend computation \textit{intelligently} \ilan{no need to italicize}. 
% Specifically, we build confidence intervals for each $\Delta TD_i$ and only sample additional reference points $x_{\rm ref}$s for the most promising candidates, as determined by those with low confidence intervals for $\Delta TD_i$. 
% Intuitively, we do not spend unnecessary computations and distance calculations for those points which have a very high corresponding$\Delta TD_i$; such points are not valuable to investigate as potential medoids. ${x_i}$ is assigned as the $k^{th}$ medoid if and only if its corresponding confidence interval $[\Delta TD_i - C_i(t), \Delta TD_i + C_i(t)]$ is both lower than and disjoint from any other confidence interval.

% \ilan{
% I feel like we already chatted about this in the past, but would it make sense to use the same $x_{\rm ref}$ for all candidate medoids in BUILD? 
% I think that's a natural question that a reader may have when reading through the algorithm.
% }


% The UltraPAM SWAP step is similar to the BUILD step. 
% \ilan{we probably shouldn't say that as the SWAP step is arguably more complicated, and we don't want to trivialize our contribution}
% In the SWAP step, the algorithm attempts to identify the \textit{medoid-nonmedoid pair} $(x_m, x_i)$ for which removing $x_m$ as a medoid and assigning $x_i$ as a medoid would lower the total loss the most. Intuitively, each of the $k(N-k)$ such pairs $(x_m, x_i)$ are viewed as "arms", and pulling an arm corresponds to computing the change in total loss Eq. 3 that would be induced for a single reference point $x_{\rm ref}$. As before, we build initial confidence intervals $[\Delta TD_{i,j} - C_{i,j}(t), \Delta TD_{i,j} + C_{i,j}(t)]$ for each medoid-nonmedoid pair (hence the two subscripts to $\Delta TD_{i,j}$ and $C_{i,j}(t)$, and continue to sample those that have "low" confidence intervals (specifically, those that overlap with the current lowest confidence interval). A SWAP is performed when a single confidence interval, corresponding to a specific medoid-nonmedoid pair $(x_m, x_i)$, is lower than and disjoint from all other confidence intervals; $x_m$ is then removed as a medoid and $x_i$ is designated a medoid. The SWAP step is iterated until convergence, when no more swaps can be performed to lower the total loss.

% We also note a small point of potential confusion: though our algorithm is inspired by the \textit{Upper} Confidence Bound (UCB) algorithm from the MAB literature, in our setting we are attempting to find the \textit{lowest} confidence bound to find the operation (build or swap) which will lower our total loss the most.

% Intuitively, UltraPAM only performs additional distance computations on the most promising points to assign as medoids in the BUILD step, and the most promising swaps to perform in the SWAP steps, thereby saving computation on unpromising candidates. In the following sections, we formalize this argument and provide theoretical guarantees under which UltraPAM will return the same results as PAM and FastPAM. We also experimentally validate our approach on several real-world datasets.


% \begin{algorithm}[t]
% \caption{\texttt{\algnamenospace.BUILD($X, k, d, batch\_size$):} 
% %\Comment{Dataset $X$ of size $N$, number of medoids $k_{max}$, distance function $d$} 
% \label{alg:ultrapam-build}}
% \begin{algorithmic}[1]
% \For{$l = 1, 2, ..., k$}
%     \State $\mathcal{M} = \emptyset$
%     \State $arms \leftarrow [n]$
%     \State $T \leftarrow (0, \dots, 0)$ \Comment{Number of times each arm has been pulled}
%     \State $B, M, U = (-\infty, \dots, -\infty), (0, 0, 0), (\infty, \dots, \infty)$ \Comment{Initial means and confidence bounds}
%     \State Draw a sample of $batch\_size$ reference points, $\{x_{\rm ref}\}$, uniformly at random
%     \ForAll{arms $i$}
%     \State $\sigma_i$ $\leftarrow$ STDEV($\{\Delta L_{x_i}(x_{\rm ref})\}$) \Comment{Estimate $\sigma_i$} for each arm
%     \EndFor
    
%     \While{$arms \neq \emptyset$}
%         % Question: should we even include this case in the pseudocode?
%         \ForAll{arms $i$ where $T_i + batch\_size \geq N$} \State Compute $\sum_{j = 1}^N \Delta L_{x_i}(x_j)$ exactly \Comment Over all datapoints
%         \State Set $B_i = M_i = U_i = \sum_{j = 1}^N \Delta L_{x_i}(x_j)$ \Comment Arm return is known exactly
%         \EndFor
%         \State Draw a new sample of $batch\_size$ reference points, $\{x_{\rm ref}\}$, uniformly at random
%         \ForAll{arms $i$ where $T_i + batch\_size < N$}
%         \State $M_i \leftarrow \frac{ T_iM_i + \sum_{x_{\rm ref}}\Delta L_{x_i}(x_{\rm ref})}{T_i + batch\_size}$ \Comment{Update running average}
%         \State $T_i \leftarrow T_i + batch\_size$
%         \State $C_i \leftarrow \sigma_i \sqrt{ \frac{ \log(\frac{1}{\delta}) } {T_i}}$
%         \State $B_i \leftarrow M_i - C_i$, $U_i \leftarrow M_i + C_i$ \Comment{Update confidence interval}
%         \EndFor

%     \State $arms \leftarrow \{i : B_i \leq \min_i(U_i)\}$ \Comment{Arms to pull must overlap with lowest CI}
%     \EndWhile
%     \State Append $x_i$ to $\mathcal{M}$, where $i = \argmin_iB_i$
% \EndFor
% \State \textbf{return} $\mathcal{M}$
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[t]
% \caption{\texttt{\algnamenospace.SWAP($X, \mathcal{M}, d, batch\_size$):} 
% %\Comment{Dataset $X$ of size $N$, number of medoids $k_{max}$, distance function $d$} 
% \label{alg:ultrapam-swap}}
% \begin{algorithmic}[1]
% \Repeat
%     \State $arms \leftarrow \mathcal{\mathcal{M} \times (\mathcal{X} \setminus \mathcal{M})}$ \Comment Arms are indexed by tuple $(m, o)$
%     \State $T \leftarrow (0, \dots, 0)$ \Comment{Number of times each arm has been pulled}
%     \State $B, M, U = (-\infty, \dots, -\infty), (0, 0, 0), (\infty, \dots, \infty)$ \Comment{Initial means and confidence bounds}
%     \State Draw a sample of $batch\_size$ reference points, $\{x_{\rm ref}\}$, uniformly at random
%     \ForAll{arms ${(m,o)}$}
%     \State $\sigma_{(m,o)}$ $\leftarrow$ STDEV($\{\Delta L_{(m, o)}(x_{\rm ref})\}$) \Comment{Estimate $\sigma_i$} for each arm
%     \EndFor
%     \While{$arms \neq \emptyset$}
%         % Question: should we even include this case in the pseudocode?
%         \ForAll{arms $(m, o)$ where $T_{(m,o)} + batch\_size \geq N$ } \State Compute $\sum_{j = 1}^N \Delta L_{(m, o)}(x_j)$ exactly
%         \State Set $B_{(m, o)} = M_{(m, o)} = U_{(m, o)} = \sum_{j = 1}^N \Delta L_{(m, o)}(x_j)$
%         \EndFor
%         \State Draw a new sample of $batch\_size$ reference points, $\{x_{\rm ref}\}$, uniformly at random
%         \ForAll{arms $(m, o)$ where $T_{(m,o)} + batch\_size < N$}
%         \State $M_{(m, o)} \leftarrow \frac{ T_{(m, o)}M_{(m, o)} + \sum_{x_{\rm ref}}\Delta L_{(m, o)}(x_{\rm ref})}{T_{(m, o)} + batch\_size}$ \Comment{Update running mean}
%         \State $C_{(m, o)} \leftarrow \sigma \sqrt{ \frac{ \log(\frac{1}{\delta}) } {T_i}}$
%         \State $B_{(m, o)} \leftarrow M_{(m, o)} - C_{(m, o)}$ \Comment{Update LCB}
%         \State $U_{(m, o)} \leftarrow M_{(m, o)} + C_{(m, o)}$ \Comment{Update UCB}
%         \State $T_{(m, o)} \leftarrow T_{(m, o)} + batch\_size$
%         \EndFor

%     \State $arms \leftarrow \{(m, o) : L_{(m, o)} \leq \min_{(m, o)}U_{(m,o)}\}$ \Comment{Arms must overlap with lowest CI}
%     \EndWhile
%     \State Remove $m$ from $\mathcal{M}$ and add $o$ to $\mathcal{M}$ \Comment{Perform the best swap}
% \Until{convergence}
% \State \textbf{return} $\mathcal{M}$
% \end{algorithmic}
% \end{algorithm}